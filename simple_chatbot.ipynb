{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, Audio, display, update_display\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb608d5-fd51-43b5-af93-a87b6c81825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"Openai API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9112b5a-cfab-415b-9070-f28cf638a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc417385-4ca1-4078-b362-6d30689fe809",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_prices = {\"gemini\": \"free\", \"openai\": \"minimum 5$\", \"claude\": \"20$\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24719fbb-ca5e-4e22-b1d1-25c78634209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subscription_price(name):\n",
    "    model_name = name.lower()\n",
    "    return subscription_prices.get(model_name, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6e738-7a7f-42b2-ad56-0dac7fb72ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_function = {\n",
    "    \"name\": \"get_subscription_price\",\n",
    "    \"description\": \"Get the price of an AI producer plan. Call this whenever you need to know the AI price, for example when a customer asks 'How much is for gemini'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\": \"string\", \n",
    "                \"description\": \"AI environment producer name whose AI customer want to buy\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"name\"],\n",
    "        \"additionalProperties\": False\n",
    "    }        \n",
    "}\n",
    "tools = [{\"type\": \"function\", \"function\": subscription_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d130598-714f-430f-87a4-5d5aba83a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(model_name):\n",
    "    try:\n",
    "        image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=f\"An image representing creative vision of {model_name}, showing people surrounding main object. Try to place everywhere everything unique about {model_name}, in a vibrant pop-art style\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "        image_base64 = image_response.data[0].b64_json\n",
    "        image_data = base64.b64decode(image_base64)\n",
    "        return Image.open(BytesIO(image_data))\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74f7b4-d1ea-4b43-9b74-bbe4e632a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    try:\n",
    "        response = openai.audio.speech.create(\n",
    "            model=\"tts-1\",\n",
    "            voice=\"onyx\",\n",
    "            input=message)\n",
    "        audio_stream = BytesIO(response.content)\n",
    "        return audio_stream.getvalue()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating audio: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97604f-fb20-410b-b13d-08f1a7ac44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history, model_choice):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    image = None\n",
    "    audio_data = None\n",
    "    partial_reply = \"\"\n",
    "    \n",
    "    response = openai.chat.completions.create(model=model_choice, messages=messages, tools=tools)\n",
    "    \n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        tool_response, model_name = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(tool_response)\n",
    "        image = artist(model_name)\n",
    "        \n",
    "    stream_response = openai.chat.completions.create(model=model_choice, messages=messages, stream=True)\n",
    "    for chunk in stream_response:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            partial_reply += chunk.choices[0].delta.content\n",
    "            history[-1] = {\"role\": \"assistant\", \"content\": partial_reply} if history and history[-1].get(\"role\") == \"assistant\" else {\"role\": \"assistant\", \"content\": partial_reply}\n",
    "            yield history, image, audio_data\n",
    "    \n",
    "    audio_data = talker(partial_reply)\n",
    "    history.append({\"role\": \"assistant\", \"content\": partial_reply})\n",
    "    yield history, image, audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac39c7b-b257-4069-a09d-519f845bde9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    try:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        model_name = arguments.get('name')\n",
    "        price = get_subscription_price(model_name)\n",
    "        response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps({\"name\": model_name, \"price\": price}),\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        }\n",
    "        return response, model_name\n",
    "    except Exception as e:\n",
    "        print(f\"Tool call error: {e}\")\n",
    "        return {\"role\": \"tool\", \"content\": json.dumps({\"error\": \"Invalid tool call\"})}, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6aa8f-5343-4d90-95d4-9d916838e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio):\n",
    "    try:\n",
    "        with open(\"input_audio.mp3\", \"wb\") as f:\n",
    "            f.write(audio)\n",
    "        with open(\"input_audio.mp3\", \"rb\") as f:\n",
    "            transcription = openai.audio.transcriptions.create(model=\"whisper-1\", file=f)\n",
    "        return transcription.text\n",
    "    except Exception as e:\n",
    "        print(f\"Transcription error: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301eb1d-6004-4ffd-9e9c-fcebe666036f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    model_choice = gr.Dropdown(\n",
    "        label=\"Select Model\",\n",
    "        choices=[\"gpt-4o-mini\", \"gpt-3.5-turbo\"],\n",
    "        value=\"gpt-4o-mini\"\n",
    "    )\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    audio_output = gr.Audio(label=\"AI Response Audio\", autoplay=True)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "        audio_input = gr.Audio(sources=[\"microphone\"], type=\"numpy\", label=\"Speak your question\")\n",
    "        submit = gr.Button(\"Send\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history = history or []\n",
    "        history.append({\"role\": \"user\", \"content\": message})\n",
    "        return \"\", history\n",
    "\n",
    "    def do_audio_input(audio, history, model_choice):\n",
    "        if audio is None:\n",
    "            return history, None, None\n",
    "        transcribed = transcribe_audio(audio)\n",
    "        history = history or []\n",
    "        history.append({\"role\": \"user\", \"content\": transcribed})\n",
    "        return history, None, None\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=[chatbot, model_choice], outputs=[chatbot, image_output, audio_output]\n",
    "    )\n",
    "    audio_input.stop_recording(do_audio_input, inputs=[audio_input, chatbot, model_choice], outputs=[chatbot, image_output, audio_output]).then(\n",
    "        chat, inputs=[chatbot, model_choice], outputs=[chatbot, image_output, audio_output]\n",
    "    )\n",
    "    clear.click(lambda: (None, None, None), inputs=None, outputs=[chatbot, image_output, audio_output], queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc19f42-b5e5-46db-a9a7-c8b866b09e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a55e9-5cf8-4379-b363-a0449c531e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
